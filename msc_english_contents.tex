\chapter{Introduction}
Since 2012 computer vision research has been increasingly dominated by approaches using deep Convolutional Neural Networks (CNNs). These CNN based techniques have allowed for achieving significantly better results in computational image and video understanding compared to previous state-of-the-art approaches. Nowadays, there are many interesting avenues of computer vision research, such as image segmentation, object detection, object recognition, image captioning, pose detection, and many more. Since the task of computational image understanding is quite complex, the CNNs used to solve these problems often require dozens, if not hundreds of millions of parameters, in order to achieve sufficiently reliable accuracies. As the number of parameters is high, the networks require large computational resources to find optimal values for all of the variables in all of the hundreds of layers of matrices. Graphics Processing Units (GPUs) or Tensor Processing Units (TPUs) are the tools that people use to train the parameters in the networks since the training operations are highly parallelizable, allowing for the training of networks with hundreds or even thousands of layers. The problem often is that when training, one wants to increase the batch size, but at the same time, the computations must fit in the memory of the processing unit, which can be difficult to increase. Also, as the number of parameters in the model increases, the memory required for training the networks, and the time to produce outputs increases. To combat these problems, we often have to get better or more hardware, which can be expensive or compromise in the size of the model, which may lead to unreliable performance.

Embedded devices can use these CNN based algorithms to analyze their surroundings in an environment where they can't rely on external predictions from the cloud. One of the most significant issues is that achieving scene understanding requires multiple classifiers to solve various tasks. For example, a camera-based self-driving car has numerous things it is interested in resolving using the video output of its cameras. The tasks could be, for example, finding and classifying other vehicles, traffic signs, road markings, predicting paths of vehicles, pedestrians, and other actors, understanding where it can move and finally producing the output of steering angle and acceleration. All these tasks have to be solved using the limited computing capability onboard the actor, and the inference time for them can't be too long in order to react to everything within a reasonable time frame. Here we have many tasks, and if every task requires its independent network to produce the outputs, and we cut down on the network sizes, the classifiers might be powerful enough to produce safe outputs. On the other hand, if we don't reduce the network sizes, our inference time might be too long for a real-time system. One way to possibly get a good compromise between inference time and model complexity is to use multi-task learning and weight sharing within the model to get a single model with multiple outputs and similar or better performance to individual classifiers.

Multi-task learning proposes some solutions to these problems but makes the training process more difficult. Still, in some cases, it is something that has to be done to get a good enough inference time and accuracy on the problem at hand. Many modern computer vision models already feature an ImageNet backbone as a part of the classifier, so this is a good part of the network to consider for sharing, but finding which tasks and how much can be shared is a difficult problem to solve.

\section{Scope of study}
In this thesis, we will study state-of-the-art solutions to some computer vision problems, like image classification, object detection, and text recognition. Then we will train classifiers that solve these problems using various data sets and try to combine them to produce a single multi-task network using multi-task learning. We will then evaluate how easy and effective it is to share the weights within similar and different tasks.
\chapter{Neural networks}
Background stuff 
\section{Fully Connected Networks}
When needed example of a transfer learning head?, when good/bad
\section{Convolutional Neural Networks}
Show some basic CNN things maybe and why needed over fully connected bois :) 
\subsection{Neural image processing}
How it different from classical features and how/why it works
\section{Attention}
Attention huh
\section{Multi-task learning}
Describe how a multi-task setting differs or maybe in the other chapter only?
\section{RNN}
Depending on what may be used



\chapter{Image classification}
Image classification is one of the essential modern computer vision problems, where the goal is to create a model that can classify an input image into one of a set of pre-defined classes. Before the popularization of applying large Convolutional Neural Networks for this task, the most successful way of solving the problem was to use some algorithm for finding feature descriptors in a set of images to construct a Visual Bag of Words.  A linear classifier, like a Support Vector Machine, would then do the classification using the Bag of Words representation of an image. These days nearly all approaches are based on using deep CNNs, and working CNNs were deployed already in 1998 on character recognition in the form of LeNet \citep{leNet}.

\section{ImageNet}

ImageNet  \citep{imagenet}  is perhaps the most significant dataset for image classification and especially the ImageNet Challenge \citep{ILSVRC}, which is a challenge for a collection of 1000 classes from the ImageNet dataset for image classification using 1.2 million training and 150 thousand test images of the entire ImageNet dataset. In 2012 the winning model, AlexNet \citep{alexNet}, showed that it was possible to train a deep CNNs efficiently using GPUs. Since 2012 all top-performing models showed some new improvements on how to create the most performant network architecture, for example, VGGNet from the year 2014 and ResNet \citep{resNet} from 2015, both of which have been popular models to use for Transfer Learning since.

Human accuracy on the ImageNet challenge is about 5.1\% \citep{imageNet_summary}, and ResNet achieves a top-5 error rate of 3.57\% \citep{resNet} and newer architectures even lower, but this still does not mean that image classification is a solved problem. The human performance experiment found that many of the human errors are caused by not having expert information in, for example, identifying animal species or not even being aware of the existence of a class \citep{imageNet_summary}. ObjectNet \citep{objectNet} is a dataset designed to test image classifiers with a focus on their generalizability. It contains many classes that also exist in the ImageNet dataset. However, they are in unexpected locations or have an unexpected pose, causing the high accuracy image classifiers trained on ImageNet to experience a 40-45\% accuracy drop when evaluating them on the ObjectNet images of classes shared between ImageNet and ObjectNet. This kind of adjustment is relatively easy for a human, and it shows that while the classifiers are good, they are by no means perfect.

\section{Transfer learning}
Transfer learning is a powerful technique to obtain results quickly when using deep CNNs. Here we will only take a look at transfer learning within the domain of deep CNNs, but it is a technique that has been successfully applied to many other domains of machine learning as well.

To give a formal definition of transfer learning, we will follow the definitions provided in \citep{transferSurvey2010}. Let $\mathcal{D}$ be a domain, which consists of a feature space $\mathcal{X}$ and a marginal probability distribution P($\mathcal{X}$). For a given domain, a task $\mathcal{T}$ = {$\mathcal{Y}$, f$\mathcal(X)$} consist of a label space $\mathcal{Y}$ for the inputs and of a predictive function $f(x)$ which produces predictions for all pairs ${x_i, y_i}$ where $x_i \in \mathcal{X}$ and $y_i \in \mathcal{Y}$. Given a source domain $\mathcal{D}_S$, a source task $\mathcal{T}_S$, a target domain $\mathcal{D}_T$ and a target task $\mathcal{T}_T$, where target and source are disjoint, transfer learning tries to improve the performance of $f_T(x)$ using $\mathcal{D}_S$ and $\mathcal{T}_S$.

Unlike the ImageNet challenge, most real-world tasks do not have such an abundance of data for all possible classes. Still, to achieve the highest accuracies, they require models that are equal in terms of complexity to those that have top accuracies problems on the scale of the ImageNet classification. For this reason, many CNN classifiers, irrespective of the problem, feature one of the ImageNet classifiers in the model architecture. Even though some datasets may contain a large number of images per class, using a pre-trained classifier as a basis often produces a better final classifier by applying fine-tuning \citep{betterTransfer}.

The idea behind transfer learning is to train on a related task to the end task first. Then the network weights in the model for the actual task are initialized to those of the model we are transferring from, so the training of the original model is a pre-step to the real task. Since training the models on ImageNet scale datasets is not generally feasible due to their large number of parameters and long training time, one of the pre-trained models is picked and then fine-tuned. Fine-tuning a classifier means taking the examples for the final task, and training the network on those, updating the original classifier at the same time. The transfer learning approach differs significantly from the traditional learning model, where each task requires a separate model that learns from the given data using random weights. Since image inputs are often very high dimensional, the traditional approach may not work in many cases. The pre-training allows for focusing on data that provides answers to the actual task and not on learning low-level features, which the ImageNet classifiers would already have learned.

\begin{figure}[h!] 
\centering 
\includegraphics[width=0.8\textwidth]{imgs/imagenet_parameters.png}
\caption{Number of parameters in popular ImageNet classifiers. Figure from \citep{efficientNet}.\label{fig:params}}
\end{figure}

Picking which classifier to use as a base is often problem-dependent. As it is not possible to declare one network structure to be the best at all tasks, picking the best model to start with usually requires the user to compare different architectures and weighing the requirements for the problem at hand. Often though, the larger models will perform better, and there exists a correlation between performing well on ImageNet and being a good transfer learning model \citep{betterTransfer}. Though as can be seen in figure 3.1, better performance often comes at the cost of many more parameters, requiring more memory to train the model. Though just the number of parameters is not the only thing to compare as the throughput of a Resnet50 turns out to be about three times as large as the throughput of an EfficientNet-B4 even though they have a similar amount of parameters \citep{classifierPerformance}. So in the case of time-constrained inference environments, also the time required for an inference has to be taken into account when picking models.

If there is enough data, it turns out that using a pre-trained network does not provide any benefits in terms of the converged model accuracy, but it is not detrimental to performance either \citep{rethinkTransfer}. When training sufficiently long on a sufficient amount of data, the pre-trained and randomly initialized networks converged to similar accuracies but required significantly different amounts of training resources. Still, this does not mean that pre-training is useless by any means as the saved resources and getting models to converge faster are essential factors for progress, and of course, in many cases, training from scratch will not provide satisfying results.

\section{ResNet}
ResNet is one of the first effective and very deep Convolutional Neural Network architecture that was presented in 2015 and won the ImageNet challenge. Prior to the publication of ResNet, the most powerful networks were relatively shallow, like VGGNet, which has only 19 layers. One of the big issues relating to training deep networks is vanishing gradients, where gradients disappear when they are backpropagated through many layers \citep{wideResNet}. ResNets utilize residual connections around bottleneck building blocks, which allow for the networks to contain many more layers than those without them, the largest network presented in the original ResNet paper was 152 layers, totaling for around 8x increase in the number of layers when compared to earlier networks \citep{resNet}.

\begin{figure}[h!] 
\centering 
\includegraphics[width=0.8\textwidth]{imgs/resnet-block.png}
\caption{Resnet building block \citep{resNet}}
\end{figure}

The ResNet block architecture allows for the blocks to learn the identity function more efficiently by trying to learn the residual function instead of the direct mapping. Normally a mapping is learned between ${x}$ and ${y}$ using a function ${H(x)}$ but by the same token, we can learn a residual transformation, ${F(x) = H(x) - x}$, where ${H}$ is the mapping of two or more network layers. Both of these approaches should approximate the same functions; the difference is in how easy it is for the network to learn. Learning a transformation of ${F(x) = 0}$ would intuitively seem easier for a neural network than learning ${F(x) = x}$. As can be seen from the success of the ResNets compared to non-residual networks, this is what allows for creating very deep networks. If the transformation changes the input size, a matrix ${W}$ is necessary to map the input to the same dimensions, generating the final formula for a residual block ${y = F(x, \{W_i\}) + W_s x}$.

Many variants of ResNet exists, such as wide ResNets \citep{wideResNet}, ResNeXt \citep{resNext} and others. Also the DenseNet \citep{denseNet} is heavily inspired by ResNets. ResNet50, ResNet34, ResNet101, and ResNet152 are still some of the most popular models to use when an ImageNet trained backbone is needed for some part of a classifier as they produce good results and do not contain too many parameters compared to some other architectures.

\section{Improving model performance}
Go through depth, width, resolution, some neural architecture search

\section{EfficientNet}
EfficientNet models form a family of models ranging from EfficientNet0 to EfficientNet7 that were generated by smartly scaling existing convolutional models to optimize them for efficiency \citep{efficientNet}. The more complex models are created by using compound scaling on the EfficientNet0 model, where the width, depth, and the resolution of the network are scaled using a factor ${\phi}$. The search of ${\phi}$ is an optimization problem, where the goal is to optimize for both accuracy and number of floating-point operations. This search is only done on the base model because the neural architecture search used to find the parameter becomes very expensive as the model size increases \citep{efficientNet}.

The proposed EfficientNet models use mobile inverted bottleneck (MBConv) blocks used in MobileNetV2 \citep{mobileNetv2} in constructing the base model. The MobileNet uses a Depthwise Separable Convolution, where a depthwise convolution and a pointwise convolution are applied in sequence. The depthwise convolution applies ${d_i}$ ${k x k}$ filters to the input, where ${d_i}$ is the input channels and ${k}$ is the kernel size leading to an output channel count ${d_j = d_i}$. A normal convolutional layer would apply multiple filters having ${M}$ channels with the computational cost of ${h_i w_i d_i d_j k^2}$, whereas the depthwise convolution only has a cost of ${h_i w_i d_i (k^2 + d_j)}$, reducing the cost by ${k^2}$. The result of the depthwise convolution then runs through a pointwise convolution, where a 1 x 1 x ${d_j}$ 1d convolution is applied to get the final output as a linear combination of the channels.



\chapter{Object detection}
Based on what is going to be detected, maybe text, cars, people?
\chapter{Paragraph captioning}
Assuming we are doing this
\chapter{Multi task learning}
Cover some examples of MTL in Computer Vision, differences to Transfer Learning, why it might work, why we might see detrimental results and why it might be beneficial (results/performance)
\section{Definition}
\section{Benefits}
\section{Hard parameter sharing}
\section{Soft parameter sharing}
\section{Special multi-task approaches}
\section{Multi-task learning with little data}
\section{What and when to share}
\section{Succesful multi-task learning applications}
\chapter{Datasets}
Describing our data
\section{Data formats}
Describe what datasets are used for each of the tasks and where they are from etc.

\chapter{Experiments}
Here are our experiments
\section{Training process}
\subsection{Evaluation criterias}
eval
\section{Image classifiers}
Results of image classsifiers on the datasets maybe compare ResNet vs EfficientNet
\subsection{Only transfer learned classifier}
Just a ResNet or something
\subsection{Image classifier with attention}
Add attention to image classifier
\subsection{Classifiers combined to a multi-task model}
How it do
\section{Object detection}
Some stuff for object detection
\section{Multi-task models}
Create multi-task models for all and try to find some pairs/tuples that actually work together properly
\chapter{Result analysis}
Incredible models absolutely.

\chapter{Future work}
How to make it better what could be tried 

\chapter{Figures and Tables}

\section{Figures}
Figure~\ref{fig:logo} gives an example how to add figures to the document. Remember always to cite the figure in the main text.

\begin{figure}[h!] 
\centering 
\includegraphics[width=0.3\textwidth]{HY-logo-ml.png}
\caption{University of Helsinki flame-logo for Faculty of Science.\label{fig:logo}}
\end{figure}

\section{Tables}

Table~\ref{table:results} gives an example how to report experimental results. Remember always to cite the table in the main text. 

\begin{table}
\centering
\caption{Experimental results.\label{table:results}}
\begin{tabular}{l||l c r} 
Experiment & 1 & 2 & 3 \\ 
\hline \hline 
$A$ & 2.5 & 4.7 & -11 \\
$B$ & 8.0 & -3.7 & 12.6 \\
$A+B$ & 10.5 & 1.0 & 1.6 \\
\hline
%
\end{tabular}
\end{table}

\chapter{Citations}

\section{Citations to literature}

References are listed in a separate .bib-file. In this case it is named \texttt{bibliography.bib} including the following content:
\begin{verbatim}
@article{einstein,
    author =       "Albert Einstein",
    title =        "{Zur Elektrodynamik bewegter K{\"o}rper}. ({German})
        [{On} the electrodynamics of moving bodies]",
    journal =      "Annalen der Physik",
    volume =       "322",
    number =       "10",
    pages =        "891--921",
    year =         "1905",
    DOI =          "http://dx.doi.org/10.1002/andp.19053221004"
}
 
@book{latexcompanion,
    author    = "Michel Goossens and Frank Mittelbach and Alexander Samarin",
    title     = "The \LaTeX\ Companion",
    year      = "1993",
    publisher = "Addison-Wesley",
    address   = "Reading, Massachusetts"
}
 
@misc{knuthwebsite,
    author    = "Donald Knuth",
    title     = "Knuth: Computers and Typesetting",
    url       = "http://www-cs-faculty.stanford.edu/%7Eknuth/abcde.html"
}
1
\end{verbatim}

In the last reference url field the code \verb+%7E+ will translate into \verb+~+ once clicked in the final pdf.

References are created using command \texttt{\textbackslash cite\{einstein\}}, showing as \citep{einstein}. Other examples: \citep{latexcompanion,knuthwebsite}.

Citation style can be negotiated with the supervisor. See some options in \url{https://www.sharelatex.com/learn/Bibtex_bibliography_styles}.

\section{Crossreferences}

Appendix~\ref{appendix:model} on page~\pageref{appendix:model} contains some additional material.

\chapter{From tex to pdf}

In Linux, run \texttt{pdflatex filename.tex} and \texttt{bibtex filename.tex} repeatedly until no more warnings are shown. This process can be automised using make-command.
 
\chapter{Conclusions\label{chapter:conclusions}}

It is good to conclude with a summary of findings. You can also use separate chapter for discussion and future work. These details you can negotiate with your supervisor.