
@inproceedings{pfeiffer_visual_2019,
	location = {Cham},
	title = {Visual Person Understanding Through Multi-task and Multi-dataset Learning},
	isbn = {978-3-030-33676-9},
	doi = {10.1007/978-3-030-33676-9_39},
	series = {Lecture Notes in Computer Science},
	abstract = {We address the problem of learning a single model for person re-identification, attribute classification, body part segmentation, and pose estimation. With predictions for these tasks we gain a more holistic understanding of persons, which is valuable for many applications. This is a classical multi-task learning problem. However, no dataset exists that these tasks could be jointly learned from. Hence several datasets need to be combined during training, which in other contexts has often led to reduced performance in the past. We extensively evaluate how the different task and datasets influence each other and how different degrees of parameter sharing between the tasks affect performance. Our final model matches or outperforms its single-task counterparts without creating significant computational overhead, rendering it highly interesting for resource-constrained scenarios such as mobile robotics.},
	pages = {551--566},
	booktitle = {Pattern Recognition},
	publisher = {Springer International Publishing},
	author = {Pfeiffer, Kilian and Hermans, Alexander and Sárándi, István and Weber, Mark and Leibe, Bastian},
	editor = {Fink, Gernot A. and Frintrop, Simone and Jiang, Xiaoyi},
	date = {2019},
	langid = {english},
	file = {Springer Full Text PDF:/Users/kokutvon/Zotero/storage/85HH35JP/Pfeiffer et al. - 2019 - Visual Person Understanding Through Multi-task and.pdf:application/pdf}
}