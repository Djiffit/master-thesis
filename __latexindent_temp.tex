\chapter{Conclusions}
In this thesis, we have given an overview of fundamental computer vision tasks of image classification and object detection.
We described the importance of the ImageNet data set and some of the most significant image classification architectures based on it.
The importance of these models extend beyond just solving the ImageNet dataset, and we covered how it is possible to apply the trained models in new classification problems with transfer learning.

For object detection, we described how the problem and datasets differ from image classification ones.
We also described the different parts of object detectors and how single and two-stage detectors differ from one another and when one might be preferred over the other.
The object detectors also show how important the ImageNet backbones are, as they are an integral part of the object detection architectures also.
The focal loss is an important loss function used by modern single-stage object detectors in allowing a large number of anchor points for localizing the objects in the images.
Finally, we described one of the current state-of-the-art object detection architectures, the EfficientDet, and how it can be trained on a new problem using transfer learning like in the case of image classification.

Here we have also presented multi-task learning as a generalization of transfer learning.
In a multi-task setting, the goal is to solve multiple tasks using some shared representation. 
It differs from transfer learning in that all tasks are optimized continuously, rather than just serving as a starting point.
Doing transfer learning is an excellent way of obtaining good results, even on little data.
With multi-task training, we can utilize the common model architectures as shared parameters for multiple tasks to allow the model to generalize better and run more efficiently.
This is possible because the model is required to use the same capacity to solve multiple problems that may require different features, some of which can also be useful in other tasks. 
Still, sometimes the multi-task setting can be detrimental to accuracy.
Despite the differences in performance, utilizing shared representations means that there are fewer parameters that the model needs to learn, leading to smaller models and shorter inference times.

We saw multiple examples where multi-task learning played an important part in getting models that are efficient and performant.
One of these was the object detection, where the model tries to classify and localize the objects.
Both soft and hard parameter sharing for multi-task learning were covered, with some specialized architectures taking advantage of the fact that multiple tasks are solved at the same time.
Finally, we found that multiple tasks can serve as auxiliary targets for training to aid the model in finding important features.

A multi-task problem setting modifies the training process and introduces some new parameters that can be tuned when training models.
Task-specific sampling ratio during the data sampling process and giving task-specific loss weights were the two new factors that need to be tuned when different tasks are combined.
These weights need to be tuned appropriately for the model to be able to find the features that work for all tasks.
Beyond just tuning parameters, multi-task models may need some architectural fine-tuning in deciding which tasks should have shared representations and just how much should be shared.

The training process differences due to the multi-task problem setting were evaluated through multiple experiments on combining various datasets into a single model.
With these experiments, we empirically verified some of the assumptions of training the models in a multi-task setting.
We noted that it was difficult to find the very best models as different sampling ratios resulted in very different final models.
As the model gets larger and the number of tasks increases, finding the correct ratios gets ever more difficult.
After adding new tasks, the previous ratios might also need adjusting.
Also, we discussed the difficulties of modifying the existing models to contain our desired output heads.
This was most apparent in the case of object detectors. 
The supplied code is relatively pre-packaged to run on the specified training loop, and modifying these model definitions to add new tasks takes some effort.
We saw some improvements and reductions in the model performance, but in general, the multi-task models were close to the single-task counterparts so that reducing the model size might be a good trade-off.

In all of our experiments, we could have spent more time on them to do more trials trying over different parameters and combinations of parameters.
Maybe by doing more thorough and systematic testing, it could be possible to evaluate exactly the effect of tuning a specific parameter.
Doing all the experiments would take a long time, and it is questionable whether the results would generalize to all problems.
The fact is that there are too many things that could be tuned, so it is difficult to determine which parameter should be tested.

Multi-task learning is a significant paradigm for creating large machine learning systems.
As it isn't really scalable, nor does it really make any sense to try to solve every task separately in a system that would be called intelligent.
For example, Andrej Karpathy, the Director of AI at Tesla, has given multiple talks on how they apply multi-task learning and how it is an instrumental part of their convolutional models \citep{karpathy}.
The problems he describes their teams tackle are the same problems that we have encountered and tried to solve in this thesis.
Like deciding what tasks should share and picking the correct sampling ratios are some of the problems Karpathy brings up as some of the most significant issues in training their models.
It does make sense that a camera-based self-driving car is one of the largest current multi-task learning applications as it is a problem that benefits from all the boons of multi-task learning we have covered.
It is important to have small models for running inference in constrained environments faster than single-task counterparts.
By sharing weights between tasks that have been specially picked in a way that they can augment each other makes it easier to learn new tasks and improve performance on the existing ones.
Having separate datasets for each task allows for the easy creation of new tasks in the model irrespective of others.
The ability to modify the loss weights and task sampling ratios allows for focusing on the critical tasks that are not allowed to fail.
So, while it likely is more difficult to train a model that solves all the tasks together, it is most likely unavoidable.
Single-task models that would solve the same tasks with the same real-time requirements would likely have to be so small that they would be unusable.
These are the kinds of problems where it is impossible to avoid using multi-task learning. 
With the correct techniques, it is possible to create systems that can reliably augment people's abilities.

In the end, what we learned is that the success of creating multi-task models out of some tasks can't be pre-determined currently. 
Some expensive experimentation is needed to arrive at the best multi-task architecture and to find the optimal parameters to train the model.  
Thus, multi-task learning can be considered as a trade-off of training time complexity for inference-time benefits in accuracy and speed.