\chapter{Conclusions}
In this thesis, we have given an overview of fundamental computer vision tasks of image classification and object detection.
We described the importance of the ImageNet data set and some of the most significant image classification architectures based on it.
The importance of these models extend beyond just solving the ImageNet dataset, and we covered how it is possible to apply the trained models in new classification problems with transfer learning.

For object detection, we described how the problem and datasets differ from image classification ones.
We also described the different parts of object detectors and how single and two-stage detectors differ from one another and when one might be preferred over the other.
The object detectors also show how important the ImageNet backbones are, as they are an integral part of the object detection architectures also.
The focal loss is an important loss function used by modern single-stage object detectors in allowing a large number of anchor points for localizing the objects in the images.
Finally, we described one of the current state-of-the-art object detection architectures, the EfficientDet, and how it can be trained on a new problem using transfer learning like in the case of image classification.

Here we have also presented multi-task learning as a generalization of transfer learning.
In a multi-task setting, the goal is to solve multiple tasks using some shared representation. 
It differs from transfer learning in that all tasks are optimized continuously, rather than just serving as a starting point.
Doing transfer learning is an excellent way of obtaining good results, even on little data.
With multi-task training, we can utilize the common model architectures as shared parameters for multiple tasks to allow the model to generalize better and run more efficiently.
This is possible because the model is required to use the same capacity to solve multiple problems that may require different features, some of which can also be useful in other tasks. 
Still, sometimes the multi-task setting can be detrimental to accuracy.
Despite the differences in performance, utilizing shared representations means that there are fewer parameters that the model needs to learn, leading to smaller models and shorter inference times.

We saw multiple examples where multi-task learning played an important part in getting models that are efficient and performant.
One of these was the object detection, where the model tries to classify and localize the objects.
Both soft and hard parameter sharing for multi-task learning were covered, with some specialized architectures taking advantage of the fact that multiple tasks are solved at the same time.
Finally, we found that multiple tasks can serve as auxiliary targets for training to aid the model in finding important features.

A multi-task problem setting modifies the training process and introduces some new parameters that can be tuned when training models.
Task-specific sampling ratio during the data sampling process and giving task-specific loss weights were the two new factors that need to be tuned when different tasks are combined.
These weights need to be tuned appropriately for the model to be able to find the features that work for all tasks.
Beyond just tuning parameters, multi-task models may need some architectural fine-tuning in deciding which tasks should have shared representations and just how much should be shared.

The training process differences due to the multi-task problem setting were evaluated through multiple experiments on combining various datasets into a single model.
With these experiments, we empirically verified some of the assumptions of training the models in a multi-task setting.
We noted that it was difficult to find the very best models as different sampling ratios resulted in very different final models.
As the model gets larger and the number of tasks increases, finding the correct ratios gets ever more difficult.
After adding new tasks, the previous ratios might also need adjusting.
Also, we discussed the difficulties of modifying the existing models to contain our desired output heads.
This was most apparent in the case of object detectors. 
The supplied code is relatively pre-packaged to run on the specified training loop, and modifying these model definitions to add new tasks takes some effort.
We saw some improvements and reductions in the model performance, but in general, the multi-task models were close to the single-task counterparts so that reducing the model size might be a good trade-off.

In the end, what we learned is that the success of multi-task learning some tasks can't be pre-determined currently, and some expensive experimentation is needed to arrive at the best multi-task architecture.  
Thus, multi-task learning can be considered as a trade-off of training time complexity for inference-time benefits in accuracy and speed.